{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des librairy\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "from skimpy import skim\n",
    "import missingno as msno\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lecture des csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read des csv statiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aeronefs = pd.read_csv('dataset/aeronefs_2024-06-02.csv')\n",
    "df_composants = pd.read_csv('dataset/composants_2024-06-02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lecture et mise à jour des csv dynamiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération date du jour\n",
    "aujourdhui = date.today()\n",
    "aujourdhui = aujourdhui.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture des logs ancien et nouveau\n",
    "df_logs_old = pd.read_csv('dataset/logs_vols.csv')\n",
    "\n",
    "df_logs_new = pd.read_csv(f'http://sc-e.fr/docs/logs_vols_{aujourdhui}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation des 2 df puis suppression des doublons\n",
    "df_logs_concat = pd.concat([df_logs_old, df_logs_new], axis= 1)\n",
    "\n",
    "df_logs = df_logs_concat.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des df inutiles\n",
    "del df_logs_concat, df_logs_old, df_logs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier dataset/logs_vols.csv a été supprimé\n"
     ]
    }
   ],
   "source": [
    "# suppression de l'ancien csv\n",
    "chemin_csv = 'dataset/logs_vols.csv'\n",
    "\n",
    "if os.path.exists(chemin_csv):\n",
    "    os.remove(chemin_csv)\n",
    "    print(f\"Le fichier {chemin_csv} a été supprimé\")\n",
    "else:\n",
    "    print(f\"Le fichier {chemin_csv} n'existe pas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrement des nouvelles données dans le csv\n",
    "df_logs.to_csv('dataset/logs_vols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degradations_old = pd.read_csv('dataset/degradations.csv')\n",
    "\n",
    "df_degradations_new = pd.read_csv(f'http://sc-e.fr/docs/degradations_{aujourdhui}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation des 2 df puis suppression des doublons\n",
    "df_degradations_concat = pd.concat([df_degradations_old, df_degradations_new], axis= 1)\n",
    "\n",
    "df_degradations = df_degradations_concat.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des df inutiles\n",
    "del df_degradations_concat, df_degradations_old, df_degradations_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier dataset/degradations.csv a été supprimé\n"
     ]
    }
   ],
   "source": [
    "# suppression de l'ancien csv\n",
    "chemin_csv = 'dataset/degradations.csv'\n",
    "\n",
    "if os.path.exists(chemin_csv):\n",
    "    os.remove(chemin_csv)\n",
    "    print(f\"Le fichier {chemin_csv} a été supprimé\")\n",
    "else:\n",
    "    print(f\"Le fichier {chemin_csv} n'existe pas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrement des nouvelles données dans le csv\n",
    "df_degradations.to_csv('dataset/degradations.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
